import argparse
import os
import json
import warnings
from datetime import datetime
from stable_baselines3 import PPO
from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.vec_env import SubprocVecEnv
from stable_baselines3.common.monitor import Monitor

# -- Custom IMPORTS --
from src.workspace_manager import ExperimentWorkspace
from src import utils
from src.wrappers import DynamicRewardWrapper
from src.callbacks import AgenticObservationTracker, ComprehensiveEvalCallback
from src.evaluation import evaluate_agent
from src.config import Config # Still used for static settings like ENV_ID

warnings.filterwarnings("ignore", message=".*pkg_resources is deprecated.*")

def run_training_cycle(iteration):
    # 1. Initialize Workspace
    # This automatically latches onto the Campaign/Model from Bash
    ws = ExperimentWorkspace()
    print(f"üöÄ [Iter {iteration}] Initializing Training in: {ws.model_root_path}")

    # 2. Dynamic Code Loading
    # Logic: To train Iteration N, we need the code generated by Iteration N-1.
    # Base Case: If Iteration 1, we look for a 'seed_reward.py' in the root.
    if iteration == 1:
        reward_code_path = "seed_reward.py"
        if not os.path.exists(reward_code_path):
            raise FileNotFoundError("‚ö†Ô∏è For Iteration 1, you must have a 'seed_reward.py' in the project root!")
    else:
        # Load the code generated by the previous cycle
        reward_code_path = ws.get_path("code", iteration - 1, "reward.py")
    
    print(f"üì• Loading Reward Function from: {reward_code_path}")
    #current_reward_module = utils.load_dynamic_module("current_reward", reward_code_path)

    # 3. Setup Hardware
    n_envs, device = utils.get_hardware_config()
    ppo_params = utils.get_optimized_ppo_params(n_envs, device)

    # 4. Create Environment with Injection
    def make_env():
        import gymnasium as gym
        env = gym.make(Config.ENV_ID)
        
        # CORRECT: Passing the string path, NOT the module object
        env = DynamicRewardWrapper(env, reward_code_path=str(reward_code_path)) 
        return Monitor(env)

    # Use the workspace tensorboard path
    env = make_vec_env(make_env, n_envs=Config.N_ENVS, vec_env_cls=SubprocVecEnv)

    # 5. Initialize Callbacks
    # We use the workspace path for raw logs
    json_log_dir = ws.dirs["telemetry_raw"]
    
    supervisor_callback = AgenticObservationTracker(
        obs_indices=[4, 6, 7], 
        save_path=json_log_dir
    )
    metrics_callback = ComprehensiveEvalCallback(threshold_score=200)

    # 6. Train
    print(f"üèãÔ∏è Training on {device}...")
    model = PPO(
        "MlpPolicy",
        env,
        device=ppo_params['device'],
        n_steps=ppo_params['n_steps'],                   
        batch_size=ppo_params['batch_size'],
        tensorboard_log=str(ws.dirs["tensorboard"]),
        n_epochs=10,
        gamma=0.999,
        gae_lambda=0.98,
        ent_coef=0.01,
        verbose=0
    )
    
    # Use formatted string for TB log name
    model.learn(
        total_timesteps=Config.TOTAL_TIMESTEPS, 
        callback=[supervisor_callback, metrics_callback],
        tb_log_name=f"Iter_{iteration:03d}"
    )
    
    # 7. Save & Evaluate
    model_save_path = ws.get_path("models", iteration, "model")
    model.save(model_save_path)
    
    print("üìä Running Evaluation...")

    stats = evaluate_agent(model, run_id=iteration, num_episodes=10)
    
    # 8. Handoff to Controller (Save Metrics)
    metrics_payload = {
        "timestamp": datetime.now().isoformat(),
        "iteration": iteration,
        "config": {"total_timesteps": Config.TOTAL_TIMESTEPS},
        "performance": stats,
        "source_code_path": str(reward_code_path)
    }
    
    ws.save_metrics(iteration, metrics_payload)
    print(f"‚úÖ Training Cycle Complete. Metrics passed to Controller.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--iteration", type=int, required=True)
    args = parser.parse_args()
    
    run_training_cycle(args.iteration)