# Generated by qwen2.5-coder:7b (Iter 1) on 2025-12-19 13:46:02
# reward_shaping.py

import numpy as np
import math

def calculate_reward(observation, original_reward, terminated, truncated, info):
    """
    Args:
        observation (np.array): State vector (LunarLander has 8 values).
        original_reward (float): Reward from the env.
        terminated (bool): Crash or Landed.
        truncated (bool): Timeout.
        info (dict): Diagnostic info.
    """
    
    # ---------------------------------------------------------
    # AGENT LOGIC GOES HERE
    # ---------------------------------------------------------
    
    x_position, y_position, vertical_velocity, tilt_angle, main_engine_usage, side_engine_usage = observation

    shaped_reward = original_reward
    
    # Positive Reward for Successful Landing
    if terminated and not truncated:
        if -1.0 <= x_position <= 1.0 and abs(vertical_velocity) < 0.5:
            shaped_reward += 100  # High reward for successful landing

    # Negative Reward for Crashes and Excessive Tilt
    if terminated and truncated or tilt_angle > 10:
        shaped_reward -= 50  # Penalty for crashes or excessive tilt
    
    # Penalty for Off-Center Landing
    if abs(x_position) > 1.0:
        shaped_reward -= 20  # Penalty for landing off-center

    # Penalty for Imbalanced Engine Usage
    if main_engine_usage < 0.1 or main_engine_usage > 0.8 or side_engine_usage > 0.5:
        shaped_reward -= 20  # Penalty for imbalanced engine usage
    
    return shaped_reward