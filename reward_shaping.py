# Generated by deepseek-coder:6.7b (Iter 10) on 2025-12-19 21:35:39
# Generated by deepseek-coder:6.7b 2025-12-19 21:34:46
def calculate_reward(observation, original_reward, terminated, truncated, info):
    """
    Args:
        observation     (np.array): State vector       (LunarLander has 8 values).
        original_reward (float)   : Reward from the env.
        terminated      (bool)    : Crash or Landed.
        truncated       (bool)    : Timeout.
        info            (dict)    : Diagnostic info.
    
    Returns:
        float: Shaped reward based on given conditions and coefficients.
    """
    
    shaped_reward = original_reward  # Initialize shaped reward as the original one

    if 'y_position' in info and 'angle' in info:
        
        # Increase reward for landing near lunar surface, preferably at y=0 (decrease)
        shaped_reward += -abs(info['y_position']) * 5  
        
        if 'vy' in info:
            # Decrease reward proportionally to vertical velocity. This will encourage the agent to decrease vertical velocity, i.e., land on the lunar surface successfully.
            shaped_reward += -abs(info['vy']) * 3  
            
        # Increase reward for smaller angle of inclination, preferably near zero
        shaped_reward += -abs(info['angle']) * 2  
        
    if 'main_engine' in info:
        # Decrease penalties proportionally to the main engine usage. This will discourage excessive use of the engines and encourage safe control of descent rate and altitude.
        shaped_reward -= abs(info['vy']) * 0.1 if 'vy' in info else 0
        
        # Add penalties for exceeding the maximum height or speed limits to ensure safety. This encourages controlled performance.
        shaped_reward -= abs(info['main<｜begin▁of▁sentence｜>engine']) * 0.2 if '<｜begin▁of▁sentence｜>engine' in info else 0
        
    return max(shaped_reward, original_reward)