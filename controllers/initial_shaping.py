import argparse
import ollama
import warnings
import time
from datetime import datetime, timedelta 
import os
import sys
warnings.filterwarnings("ignore", message=".*pkg_resources is deprecated.*")

# -- PROJECT IMPORTS --
import prompts  
from src.workspace_manager import ExperimentWorkspace
from src.code_validation import CodeValidator
from src import utils
from src.config import Config
from src.llm_utils import *

MODEL_NAME = Config.LLM_MODEL
# Enabling thinking trace based on model name
think_flag = get_thinking_flag(MODEL_NAME)


def get_inital_shaping():
    # For catching excution time at the end 
    start_time = time.perf_counter()

    # 1. Initialize Workspace
    ws = ExperimentWorkspace()
    cognition_json_path = ws.get_path("cognition_json", 0, "cognition_record.json") # Where to save JSON of cognition
    save_path = ws.get_path("code", 0, "reward.py") # Where we will save generated code to be accessed by train.py script
    cognition_iter = init_cognition_iteration(iteration=0, model_name=MODEL_NAME)

    

    role, task = prompts.build_initial_shaping_prompt(Config.code_zero_template)
    try:
        response = ollama.chat(
            model = MODEL_NAME,
            messages = [
                {'role':'system', 'content': role},
                {'role':'user', 'content': task}
            ],
            options = Config.coder_options,
            think= think_flag
        )
    except Exception as e:
        print(f"❌ Initial Reward Function Generation Error:\n {e}")
        sys.exit()
        return

        # Saving input prompts and responses as easy to read Markdown documents for later
    cognition_list = []
    cognition_list.append((f"LLM Input: `role` using {Config.code_zero_template[0]}.md",role))
    cognition_list.append((f"LLM Input: `task` using {Config.code_zero_template[1]}.md",task))
    cognition_list.append(("LLM Output: thinking",response['message']['thinking']))
    cognition_list.append(("LLM Output: plan",response['message']['content']))

    append_chatresponse_row(
        csv_path =ws.containers['cognition_csv'], 
        model_name=MODEL_NAME, 
        response=response,
        run_id = f"Iter_00_code", 
        iteration=0, 
        phase="Phase_0", 
        prompt_type="code_gen",
        prompt_template_roles=f"{Config.code_zero_template[0]}.md",
        prompt_template_tasks=f"{Config.code_zero_template[1]}.md",
        cognition_path=cognition_json_path)

    # Saves full prompts/responses of LLM to JSON, One JSON per iteration
    add_cognition_call(
        cognition_iter=cognition_iter,
        response=response,
        run_id=f"Iter_00_code",
        phase="code_gen",
        system_role=role,
        user_task=task,
        options=Config.coder_options,
        prompt_template_roles=f"{Config.code_zero_template[0]}.md",
        prompt_template_tasks=f"{Config.code_zero_template[1]}.md",)
    
    clean_code = utils.extract_python_code(response['message']['content'])
        
    validator = CodeValidator(clean_code)
    is_valid, feedback = validator.validate_static()
    if is_valid: 
        is_valid, feedback = validator.validate_runtime(strict_mode = False)
        if not is_valid:
            print("*"*20)
            print("Initial generated code failed runtime analysis")
            print("*"*20)

    else:
        print("*"*20)
        print("Initial generated code failed static analysis")
        print("*"*20)

    
    # Save code to file to train the first iteration agent
    timestamp_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    header = f"# Generated by {MODEL_NAME} (Iter {0}) on {timestamp_str}\n"
    final_content = header + clean_code
    try:
        with open(save_path, "w") as f:
            f.write(final_content)
        if is_valid:
            print(f"✅ Code validated and saved.")
    except Exception as e:
        print(f"❌ Phase 0, Error saving code: {e}")

    # Save cognition history in easy read markdown documents 
    utils.save_cognition_markdown(ws,0, cognition_list)

    elapsed_time =time.perf_counter()-start_time
    print(f"Execution took: {timedelta(seconds=elapsed_time)}")



if __name__ == "__main__":
    get_inital_shaping()