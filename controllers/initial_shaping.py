import argparse
import ollama
import warnings
import time
from datetime import datetime, timedelta 
import os
import sys
warnings.filterwarnings("ignore", message=".*pkg_resources is deprecated.*")

# -- PROJECT IMPORTS --
import prompts  
from src.workspace_manager import ExperimentWorkspace
from src.code_validation import CodeValidator
from src import utils
from src.config import Config
from src.llm_utils import *
from src.cognitive_node import CognitiveNode

MODEL_NAME = "gpt-oss:20b"
# Enabling thinking trace based on model name
think_flag = False #get_thinking_flag(MODEL_NAME)


def get_inital_shaping():
    # For catching excution time at the end 
    start_time = time.perf_counter()

    # 1. Initialize Workspace
    ws = ExperimentWorkspace()
    brain = CognitiveNode(iteration = 0 , workspace = ws, model = MODEL_NAME)
    save_path = ws.get_path("code", 0, "reward.py") # Where we will save generated code to be accessed by train.py script
 

    

    role, task = prompts.build_initial_shaping_prompt(Config.code_zero_template)

    response = brain.chat(phase_name='initial',
                                system_prompt=role,
                                user_prompt=task,
                                parse_json=False,
                                options=Config.get_coder_options(MODEL_NAME))
    
    # Imports are hit or miss with LLMs, best to just add them in to avoid failing code validation over missing imports
    clean_code = f"import numpy as np\nimport math\n" 
    clean_code += utils.extract_python_code(response)
        
    validator = CodeValidator(clean_code)
    is_valid, feedback = validator.validate_static()
    if is_valid: 
        is_valid, feedback = validator.validate_runtime(strict_mode = False)
        if not is_valid:
            print("*"*20)
            print("Initial generated code failed runtime analysis")
            print("*"*20)
            print(f"{feedback}")
            print("*"*20)

    else:
        print("*"*20)
        print("Initial generated code failed static analysis")
        print("*"*20)
        print(f"{feedback}")
        print("*"*20)

    # --- RETRY LOOP ---
    # This runs if validation failed OR if an exception occurred above
    attempt_num = 0
    while not is_valid and attempt_num < 3:
        attempt_num += 1
        print(f"âš ï¸ Validation failed (Attempt {attempt_num}). Feedback: {feedback}")
        
        # Save to the 'failed_code' directory defined in Workspace
        fail_filename = f"fail_{attempt_num:02d}.py"
        fail_path = ws.get_path("failed_code", 0, fail_filename)
        
        if attempt_num == 1:
            with open(fail_path, "w") as f:
                f.write(f"# Error: {feedback}\n")
                f.write(clean_code)
            
        print(f"ðŸ”§ Fixing Code...")
        
        fix_role, fix_task = prompts.build_fix_prompt(Config.code_fix_template,clean_code, feedback)
        
        # LLM code self-correction call
        code_fix_response = brain.chat(phase_name='code_fix',
                                       system_prompt=fix_role,
                                       user_prompt=fix_task,
                                       parse_json=False,
                                       options=Config.get_coder_options(MODEL_NAME))
        clean_code = f"import numpy as np\nimport math\n" 
        clean_code = utils.extract_python_code(code_fix_response)
        validator = CodeValidator(clean_code)
        is_valid, feedback = validator.validate_static()

        if is_valid:
            is_valid, feedback = validator.validate_runtime()
    # Save code to file to train the first iteration agent
    timestamp_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    header = f"# Generated by {MODEL_NAME} (Iter {0}) on {timestamp_str}\n"
    final_content = header + clean_code
    try:
        with open(save_path, "w") as f:
            f.write(final_content)
        if is_valid:
            print(f"âœ… Code validated and saved.")
    except Exception as e:
        print(f"âŒ Phase 0, Error saving code: {e}")

    # Save cognition markdown 
    brain.save_report()

    elapsed_time =time.perf_counter()-start_time
    print(f"Execution took: {timedelta(seconds=elapsed_time)}")



if __name__ == "__main__":
    get_inital_shaping()